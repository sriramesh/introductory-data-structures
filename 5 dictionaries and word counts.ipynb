{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary of all of the files in the 'data' sub-directory\n",
    "\n",
    "DIRECTORY = 'data/'\n",
    "\n",
    "# function to get a list of file names of interest\n",
    "def getRelevantFiles(string):\n",
    "    directory = [f for f in listdir(DIRECTORY) if isfile(join(DIRECTORY, f))] # all files in given directory \n",
    "    files_of_interest = [] # get a sublist of only the relevant files within given directory\n",
    "    if string == 'pk': # if string == 'pk' get sub-list of elements with pk prefix\n",
    "        for i in directory:\n",
    "            if ( i[:2] == 'pk' ):\n",
    "                files_of_interest.append(i) # \n",
    "\n",
    "    elif string == 'dr': # same for dr prefix\n",
    "        for i in directory:\n",
    "            if ( i[:2] == 'dr' ):\n",
    "                files_of_interest.append(i)\n",
    "\n",
    "    elif string == \"\": # if string ==\"\", sub-list is all files in directory\n",
    "        for i in directory:\n",
    "            files_of_interest.append(i)\n",
    "\n",
    "    else:\n",
    "        i = string + '.txt'\n",
    "        files_of_interest.append(i) # append just this text file. files_of_interest is now just an atomic list\n",
    "    return files_of_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dictionary( D ): # sort dictionary from most to least frequent entry count\n",
    "    Ds = sorted(D.items(), key=lambda x:x[1], reverse=True) # DS is a list with length = number of key-value pairs              \n",
    "    \n",
    "    return Ds\n",
    "\n",
    "def stripWord( w ): # strip word of punctuation and convert to all lower-case\n",
    "    w = w.replace( \".\", \"\" )\n",
    "    w = w.replace( \",\", \"\" )\n",
    "    w = w.replace( \";\", \"\" )\n",
    "    w = w.replace( \":\", \"\" )\n",
    "    w = w.replace( \"'\", \"\" )\n",
    "    w = w.replace( \"&\", \"\" )\n",
    "    w = w.replace( \"\\n\", \"\" )\n",
    "    w = w.lower()\n",
    "    \n",
    "    return( w )\n",
    "\n",
    "def build_dictionary(string): # build dictionary given file specification\n",
    "    \n",
    "    files_of_interest = getRelevantFiles(string)\n",
    "    dictionary = {} \n",
    "    N = 0\n",
    "\n",
    "    for i in files_of_interest:\n",
    "        myfile = open( 'data/' + i, 'r' )\n",
    "\n",
    "        for line in myfile: # read one line at a time\n",
    "            words = line.split(\" \") # for each line split the line into individual words that are separated by spaces\n",
    "            for w in words:\n",
    "                w = stripWord( w ) #  For each word on each line, remove any punctuation and convert to lower case\n",
    "                if( len(w) > 0 and w != '—'): # # if the word has a non-zero amount of characters\n",
    "                    N += 1 # keep track of the total number of words (N) in the document\n",
    "                    if w in dictionary: \n",
    "                        dictionary[w] += 1 # Otherwise, if a word is in your dictionary, then increment its count by 1.\n",
    "                    else:\n",
    "                        dictionary[w] = 1 # If it is not in the dictionary, then add it and set the count to 1.\n",
    "        myfile.close() \n",
    "        \n",
    "    for key, value in dictionary.items(): # convert counts to percentages\n",
    "        dictionary[key] = dictionary[key] * ( 100/N )\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def sort_dictionary( D ): # sort dictionary from most to least frequent entry count\n",
    "    Ds = sorted(D.items(), key=lambda x:x[1], reverse=True) # DS is a list with length = number of key-value pairs              \n",
    "    \n",
    "    return Ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary_count(string): # modify build_dictionary to print the frequency count of each key-value pair\n",
    "    \n",
    "    files_of_interest = getRelevantFiles(string)\n",
    "    dictionary = {}\n",
    "    N = 0\n",
    "\n",
    "    for i in files_of_interest:\n",
    "        myfile = open( 'data/' + i, 'r' )\n",
    "\n",
    "        for line in myfile: # read one line at a time\n",
    "            words = line.split(\" \") # for each line split the line into individual words that are separated by spaces\n",
    "            for w in words:\n",
    "                w = stripWord( w ) #  For each word on each line, remove any punctuation and convert to lower case\n",
    "                if( len(w) > 0 and w != '—'): # # if the word has a non-zero amount of characters\n",
    "                    N += 1 # keep track of the total number of words (N) in the document\n",
    "                    if w in dictionary: \n",
    "                        dictionary[w] += 1 # Otherwise, if a word is in your dictionary, then increment its count by 1.\n",
    "                    else:\n",
    "                        dictionary[w] = 1 # If it is not in the dictionary, then add it and set the count to 1.\n",
    "        myfile.close() \n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def print_dictionary( D ):\n",
    "    DS = sorted(D.items(), key=lambda x:x[1]) # DS is a list with length = # of key-value pairs\n",
    "    for k in DS: # for each key-value pair (where k is a tuple of len 2)\n",
    "        print(k[0], k[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver code\n",
    "\n",
    "print(getRelevantFiles('pk')) # getRelevantFiles\n",
    "print(getRelevantFiles(''))\n",
    "print(getRelevantFiles('dr2'))\n",
    "D = build_dictionary(\"pk\") # build_dictionary\n",
    "sort_dictionary(D) # sort_dictionary\n",
    "D = build_dictionary_count(\"pk\") # build_dictionary_count\n",
    "print_dictionary(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary of the top 25 most frequent words across all 18 pk and dr files in the 'data' sub-directory\n",
    "\n",
    "D = build_dictionary(\"\") # get all 18 files\n",
    "top_25 = sort_dictionary(D)[0:25] # sort and get top 25 most frequent words and their frequencies\n",
    "top_25_words = [] # get top 25 words using output from Q4\n",
    "for i in range(0, len(top_25)):\n",
    "    top_25_words.append(top_25[i][0])\n",
    "    \n",
    "print(top_25_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_matrices(string): # populate 9 by 25 matrix with top 25 words by frequency across all 18 pk and dr files\n",
    "    \n",
    "    matrix = np.zeros((9,25))\n",
    "    \n",
    "    files_of_interest = getRelevantFiles(string) # get files of interest using helper function\n",
    "    files_of_interest = [x[:-4] for x in files_of_interest]\n",
    "\n",
    "    for i in range(0, len(files_of_interest)):\n",
    "        D = build_dictionary(files_of_interest[i])\n",
    "        \n",
    "        for j in range(0, len(top_25_words)): \n",
    "            x = top_25_words[j] in D.keys()\n",
    "            if x == True:\n",
    "                matrix[i][j] = int(D[top_25_words[j]])\n",
    "            else:\n",
    "                matrix[i][j] = int(0)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "F1 = populate_matrices('pk')\n",
    "F2 = populate_matrices('dr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction and visualization\n",
    "F   = np.concatenate((F1,F2),axis=0)\n",
    "pca = PCA(n_components=2)\n",
    "Fp  = pca.fit(F).transform(F)\n",
    "plt.scatter( Fp[0:9,0], Fp[0:9,1], color='b')\n",
    "plt.scatter( Fp[9:18,0], Fp[9:18,1], color='r' )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
